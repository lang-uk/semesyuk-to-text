{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8cfa586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T21:09:34.210522Z",
     "start_time": "2022-04-17T21:09:34.203867Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from typing import Union, List, Set\n",
    "from pathlib import Path\n",
    "import string\n",
    "import statistics\n",
    "import logging\n",
    "from csv import DictWriter\n",
    "\n",
    "\n",
    "from vosk import Model as VoskModel, KaldiRecognizer, SetLogLevel\n",
    "from ffmpy import FFmpeg\n",
    "from fuzzysearch import find_near_matches\n",
    "from fuzzysearch.common import Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad2951a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T17:37:36.266970Z",
     "start_time": "2022-04-17T17:37:36.263223Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1c338fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T17:49:33.210871Z",
     "start_time": "2022-04-17T17:49:33.199957Z"
    }
   },
   "outputs": [],
   "source": [
    "class AbstractTranscriber:\n",
    "    def transcribe_audio(self, audio):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def downsample_audio(self, audio: Path):\n",
    "        downsampled_path = audio.with_name(audio.stem + \".downsampled.wav\")\n",
    "        ff = FFmpeg(\n",
    "            inputs={\n",
    "                str(audio): [\n",
    "                    \"-nostdin\",\n",
    "                    \"-loglevel\",\n",
    "                    \"quiet\",\n",
    "                    \"-y\",  # Overwrite the file if exists\n",
    "                ]\n",
    "            },\n",
    "            outputs={str(downsampled_path): [\"-ar\", str(self.sample_rate), \"-ac\", \"1\"]},\n",
    "        )\n",
    "\n",
    "        ff.run()\n",
    "\n",
    "        return downsampled_path\n",
    "\n",
    "\n",
    "class VoskTranscriber(AbstractTranscriber):\n",
    "    def __init__(self, model_path: Path, sample_rate: int = 16000) -> None:\n",
    "        self._model = VoskModel(str(model_path))\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def transcribe_audio(self, audio, vocab: Union[List[str], None] = None):\n",
    "        if vocab is None:\n",
    "            rec = KaldiRecognizer(self._model, self.sample_rate)\n",
    "        else:\n",
    "            rec = KaldiRecognizer(\n",
    "                self._model,\n",
    "                self.sample_rate,\n",
    "                json.dumps(sorted(vocab), ensure_ascii=False),\n",
    "            )\n",
    "        rec.SetWords(True)\n",
    "\n",
    "        downsampled_audio = self.downsample_audio(audio)\n",
    "        results = []\n",
    "        with open(downsampled_audio, \"rb\") as wf:\n",
    "            wf.read(44)  # skip header\n",
    "            while True:\n",
    "                data = wf.read(4000)\n",
    "                if len(data) == 0:\n",
    "                    break\n",
    "                if rec.AcceptWaveform(data):\n",
    "                    results += json.loads(rec.Result()).get(\"result\", [])\n",
    "\n",
    "            results += json.loads(rec.FinalResult()).get(\"result\", [])\n",
    "\n",
    "        downsampled_audio.unlink()\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ac6ccbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T17:55:20.883010Z",
     "start_time": "2022-04-17T17:55:14.633151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:CompileLooped():nnet-compile-looped.cc:345) Spent 0.102953 seconds in looped compilation.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk/uk-large//ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:278) Loading HCLG from models/vosk/uk-large//graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:293) Loading words from models/vosk/uk-large//graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:302) Loading winfo models/vosk/uk-large//graph/phones/word_boundary.int\n"
     ]
    }
   ],
   "source": [
    "vosk = VoskTranscriber(\"models/vosk/uk-large/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a270905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T21:24:15.164662Z",
     "start_time": "2022-04-17T21:24:15.140071Z"
    }
   },
   "outputs": [],
   "source": [
    "PUNCTUATION_TO_DROP = set(\n",
    "    string.punctuation + \"—–‒‐⁃﹣－᠆’…«‹»›„“‟”’❝❞❮❯〝〞〟＂‚‘‛❛❜\"\n",
    ") - set(\n",
    "    \"'\"\n",
    ")  # Removing standard ukrainian apostrophe\n",
    "\n",
    "\n",
    "class DatasetExtractor:\n",
    "    def __init__(self, model: AbstractTranscriber):\n",
    "        self.model = model\n",
    "\n",
    "    def transcribe_and_align(\n",
    "        self,\n",
    "        audio: Path,\n",
    "        text: Path,\n",
    "        token_separator: str = \" \",\n",
    "        punctuation_to_drop: Set[str] = PUNCTUATION_TO_DROP,\n",
    "    ) -> List[dict]:\n",
    "        transcribed = self.model.transcribe_audio(audio)\n",
    "        transcribed_text = \" \".join(r[\"word\"] for r in transcribed)\n",
    "\n",
    "        sent_matches = []\n",
    "\n",
    "        prev_match = None\n",
    "        not_found = 0\n",
    "        with text.open(\"r\") as fp:\n",
    "            for i, orig_sent in enumerate(filter(None, map(str.strip, fp.readlines()))):\n",
    "                orig_sent = orig_sent.replace(token_separator, \"\").strip()\n",
    "                if not orig_sent:\n",
    "                    continue\n",
    "\n",
    "                stripped_sent = re.sub(\n",
    "                    f\"[{re.escape(''.join(punctuation_to_drop))}]\", \" \", orig_sent\n",
    "                )\n",
    "                stripped_sent = re.sub(r\"\\s+\", \" \", stripped_sent).strip().lower()\n",
    "\n",
    "                for l_dist in range(0, int(len(stripped_sent) * 0.2) + 1):\n",
    "                    matches = find_near_matches(\n",
    "                        stripped_sent,\n",
    "                        transcribed_text\n",
    "                        if prev_match is None\n",
    "                        else transcribed_text[prev_match.end :],\n",
    "                        max_l_dist=l_dist,\n",
    "                    )\n",
    "\n",
    "                    if matches:\n",
    "                        adjusted_match = Match(\n",
    "                            start=matches[0].start\n",
    "                            + (0 if prev_match is None else prev_match.end + 1),\n",
    "                            end=matches[0].end\n",
    "                            + (0 if prev_match is None else prev_match.end + 1),\n",
    "                            dist=matches[0].dist,\n",
    "                            matched=matches[0].matched,\n",
    "                        )\n",
    "\n",
    "                        prev_match = adjusted_match\n",
    "                        logger.debug(f\"{stripped_sent}, {adjusted_match}\")\n",
    "\n",
    "                        start_word = transcribed_text[: adjusted_match.start].count(\" \")\n",
    "                        end_word = transcribed_text[: adjusted_match.end].count(\" \")\n",
    "\n",
    "                        sent_matches.append(\n",
    "                            {\n",
    "                                \"sent\": orig_sent,\n",
    "                                \"matches\": adjusted_match,\n",
    "                                \"stripped_sent\": stripped_sent,\n",
    "                                \"dist\": adjusted_match.dist,\n",
    "                                \"start\": transcribed[start_word][\"start\"],\n",
    "                                \"end\": transcribed[end_word][\"end\"],\n",
    "                            }\n",
    "                        )\n",
    "                        break\n",
    "                else:\n",
    "                    not_found += 1\n",
    "                    logger.warning(f\"No match found for {stripped_sent}\")\n",
    "\n",
    "            distances = [p[\"matches\"].dist for p in sent_matches]\n",
    "            distances_weighted = [\n",
    "                p[\"matches\"].dist / len(p[\"stripped_sent\"])\n",
    "                for p in sent_matches\n",
    "                if p[\"stripped_sent\"]\n",
    "            ]\n",
    "\n",
    "            logger.info(\n",
    "                f\"{len(sent_matches)} of {not_found + len(sent_matches)} sentences matched\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Distances (min/mean/median/max): {min(distances)} / {statistics.fmean(distances):0.2f} / {statistics.median(distances):0.2f} / {max(distances)}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Weighted distances (min/mean/median/max): {min(distances_weighted):0.2f} / {statistics.fmean(distances_weighted):0.2f} / {statistics.median(distances_weighted):0.2f} / {max(distances_weighted):0.2f}\"\n",
    "            )\n",
    "        return sent_matches\n",
    "\n",
    "    def slice_and_export(\n",
    "        self,\n",
    "        audio: Path,\n",
    "        matches: List[dict],\n",
    "        output_dir: Path,\n",
    "        audio_format: str = \"ogg\",\n",
    "    ):\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        dataset_file = output_dir / \"dataset.csv\"\n",
    "\n",
    "        with dataset_file.open(\"w\") as fp_out:\n",
    "            w = DictWriter(\n",
    "                fp_out,\n",
    "                fieldnames=[\n",
    "                    \"sentence\",\n",
    "                    \"audio\",\n",
    "                    \"start\",\n",
    "                    \"end\",\n",
    "                    \"stripped_sentence\",\n",
    "                    \"distance\",\n",
    "                ],\n",
    "            )\n",
    "            w.writeheader()\n",
    "\n",
    "            for i, match in enumerate(matches):\n",
    "                fragment_file = output_dir / f\"{i + 1}.{audio_format}\"\n",
    "\n",
    "                ff = FFmpeg(\n",
    "                    inputs={\n",
    "                        str(audio): [\n",
    "                            \"-nostdin\",\n",
    "                            \"-loglevel\",\n",
    "                            \"quiet\",\n",
    "                            \"-y\",  # Overwrite the file if exists\n",
    "                        ]\n",
    "                    },\n",
    "                    outputs={\n",
    "                        str(fragment_file): [\n",
    "                            \"-vn\",\n",
    "                            \"-ss\",  # Start time\n",
    "                            str(match[\"start\"]),\n",
    "                            \"-t\",  # End time\n",
    "                            str(match[\"end\"] - match[\"start\"]),\n",
    "                        ]\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                ff.run()\n",
    "\n",
    "                w.writerow(\n",
    "                    {\n",
    "                        \"sentence\": match[\"sent\"],\n",
    "                        \"stripped_sentence\": match[\"stripped_sent\"],\n",
    "                        \"distance\": match[\"dist\"],\n",
    "                        \"audio\": str(fragment_file),\n",
    "                        \"start\": match[\"start\"],\n",
    "                        \"end\": match[\"end\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "\n",
    "extractor = DatasetExtractor(vosk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08678bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T21:24:38.155320Z",
     "start_time": "2022-04-17T21:24:15.760827Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:пролог, Match(start=0, end=6, dist=0, matched='пролог')\n",
      "DEBUG:__main__:українці усіх можливих конструкцій форм і кольорів пики, Match(start=8, end=64, dist=1, matched='українці усіх можливих конструкцій форму і кольорів пики')\n",
      "DEBUG:__main__:ця мить настала і світ знову бачить видані на коштовному папері пригоди балакучої мавпи породи павіан, Match(start=65, end=166, dist=2, matched='ця мить настала і світ знову бачать видані на коштовному папері пригоди балакучою мавпи породи павіан')\n",
      "DEBUG:__main__:не кожна мавпа здатна до нормальних пригод це зрозуміло але конкретно ця цілком собі здатна оскільки набула людського життєвого досвіду і навіть вийшла за його межі, Match(start=167, end=328, dist=9, matched='не кожна мавпа здатна до нормальних пригод це зрозуміло але конкретно ця цілком собі здатна оскільки не була людського цього досвіду і навіть вийшло за його межі')\n",
      "DEBUG:__main__:сюжет мавпунського життя простий та водночас насичений драматичними епізодами кризами і боротьбою, Match(start=329, end=426, dist=7, matched='сюжетно польського життя простий та водночас насичений драматичними епізодами кризами і боротьбою')\n",
      "DEBUG:__main__:павіан має уредний характер чоловічу стать наділений схильністю до фрустрацій та рефлексій а також кмітливістю, Match(start=427, end=537, dist=5, matched='павіан має уряд не характер чоловічу стать наділений схильністю до фрустрацій та рефлексії а також кмітливістю')\n",
      "DEBUG:__main__:крім того а це важливо павіан має ім'я прізвище та по батькові, Match(start=538, end=600, dist=0, matched=\"крім того а це важливо павіан має ім'я прізвище та по батькові\")\n",
      "DEBUG:__main__:звати його томас якович сирота і це ім'я він поцупив разом із паспортними даними одного нікчеми ще на початку попередньої книжки 1 коли тікав з провінційного цирку на волю, Match(start=601, end=767, dist=6, matched=\"звати його томас якович сирота і це ім'я він поцупив разом з паспортними даними одного нікчеми ще на початку попередньої книжки коли тікав з провінційну цирку на волю\")\n",
      "DEBUG:__main__:фактично свою людську кар'єру він розпочав з крадіжки і не простої а крадіжки сенсів якщо хочете цілого світогляду, Match(start=768, end=881, dist=1, matched=\"фактично свою людську кар'єру він розпочав з крадіжки і непростої а крадіжки сенсів якщо хочете цілого світогляду\")\n",
      "DEBUG:__main__:дійсно як нам уже відомо з попередньої оповідки павіан томас потомствений цирковий кріпак усе своє життя пропрацював у мандрівному цирку що більше нагадував сізо аніж розважальний заклад, Match(start=882, end=1067, dist=6, matched='дійсно як нам уже відомо з попередній оповідки павіан томас потомствений сирковий кріпак усе своє життя пропрацював у мандрівного цирку що більше нагадував сізо аніж розважальний заклад')\n",
      "DEBUG:__main__:ночами сидячи у клітці він мріяв про волю конфліктував крізь ґрати з іншими цирковими тваринами і вчив українську мову, Match(start=1068, end=1186, dist=1, matched='ночами сидячи у клітці він мріяв про волю конфліктував крізь грати з іншими цирковими тваринами і вчив українську мову')\n",
      "DEBUG:__main__:так так шановні, Match(start=1187, end=1202, dist=1, matched='так-так шановні')\n",
      "DEBUG:__main__:окремі мавпи наділені більшими лінгвістичними здібностями ніж певна порода громадян нашої країни, Match(start=1203, end=1299, dist=1, matched='окремі мавпи наділені більшими лінгвістичними здібностями ніж певно порода громадян нашої країни')\n",
      "DEBUG:__main__:звичайно томас якович мав дуже специфічну мотивацію до вивчення мови яку йому диктувало саме середовище але на снобізм він точно не страждав, Match(start=1300, end=1439, dist=5, matched='звичайно томас якович мав дуже специфічну мотивацію до вивчення мови яку йому диктувало саме середович але нас лобізм він точно не страждав')\n",
      "DEBUG:__main__:мавпун не довіряв людям і хотів розібратися як саме вони влаштовані зсередини, Match(start=1440, end=1520, dist=3, matched='мав пункт не довіряв людям і хотів розібратися як саме вони влаштовані зсередини')\n",
      "DEBUG:__main__:просто так сталося що саме ці люди були паспортними українцями з усіма довідками та ідентифікаційними кодами, Match(start=1521, end=1631, dist=2, matched='просто так сталося що саме ці люди були б паспортними українцями з усіма довідками та ідентифікаційними кодами')\n",
      "DEBUG:__main__:отже томас українізувався через недовіру але це вже інша розмова, Match(start=1632, end=1698, dist=2, matched='отже томас українізувався через не до віру але це вже інша розмова')\n",
      "DEBUG:__main__:краще так аніж усе життя бути добросердим ідіотом і пускати ротом соціал демократичні бульбашки, Match(start=1699, end=1795, dist=5, matched='та що так аніж усе життя бути добросердим ідіотом і пускати ротом соціал демократичній бульбашки')\n",
      "DEBUG:__main__:думав томас якович і вважав себе переконаним націонал спеціалістом ким власне й був, Match(start=1796, end=1880, dist=3, matched='думав томас якович і вважав себе переконаним націонал спеціалістом крім власне і був')\n",
      "DEBUG:__main__:у мить коли мавпун знову з'являється на сторінках літературного твору він наділений ще й неабиякою упрілістю рішучістю і легким переляком, Match(start=1881, end=2006, dist=19, matched=\"у мить коли мав повну з'явився на сторінках літературного твору він наділений неабиякою у прілістю рішучістю легким переляком\")\n",
      "DEBUG:__main__:це й не дивно адже саме зараз томас якович вистрибує з нічного потяга котрий суне із шаленою швидкістю на київ бо крізь усі вагони за павіаном женуться троє мусорів з метою впаяти йому штраф у триста гривень, Match(start=2007, end=2213, dist=4, matched='це й не дивно адже саме зараз томас якович вистрибує з нічного потяга котре сула із шаленою швидкістю на київ бо крізь усі вагони за павіаном женуться троє мусорів з метою впаяти йому штраф у триста гривень')\n",
      "DEBUG:__main__:грошей між тим нема через що проїзд і став для нього безкоштовним, Match(start=2214, end=2271, dist=8, matched='між тим нема через що поїзд і став для нього безкоштовним')\n",
      "DEBUG:__main__:мусимо нагадати фрагмент епілогу з попередньої книжки бо саме в ньому закладено підмурок для нової не менш ідіотської історії, Match(start=2272, end=2397, dist=4, matched='мусимо нагадати фрагмент епілогом з попередньої книжки бо саме в ньому закладено підмурок для нової не менш ідіотську історії')\n",
      "INFO:__main__:23 of 23 sentences matched\n",
      "INFO:__main__:Distances (min/mean/median/max): 0 / 4.13 / 3.00 / 19\n",
      "INFO:__main__:Weighted distances (min/mean/median/max): 0.00 / 0.04 / 0.03 / 0.14\n"
     ]
    }
   ],
   "source": [
    "parsed = extractor.transcribe_and_align(\n",
    "    Path(\"audio/raw/semesyuk_farshrutka/01_prologue.mp3\"),\n",
    "    Path(\"texts/tokenized/semesyuk_farshrutka/01_prologue.txt\"),\n",
    "    token_separator=\"|\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c75eeb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T21:24:43.731357Z",
     "start_time": "2022-04-17T21:24:38.159489Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor.slice_and_export(\n",
    "    audio=Path(\"audio/raw/semesyuk_farshrutka/01_prologue.mp3\"),\n",
    "    matches=parsed,\n",
    "    output_dir=Path(\"audio/processed/semesyuk_farshrutka/01_prologue/\"),\n",
    "    audio_format=\"mp3\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
